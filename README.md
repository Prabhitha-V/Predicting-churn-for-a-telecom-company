# ğŸ“ Telecom Churn Prediction

This project aims to analyze and predict customer churn in the telecom industry by leveraging multiple Jupyter notebooks covering exploratory data analysis (EDA), feature engineering, and model development. The goal is to uncover the most influential factors behind churn and build machine learning models to predict and prevent customer loss.

---

## ğŸ¯ Project Objectives

- Identify the key factors contributing to customer churn
- Use data-driven insights to help reduce churn and improve retention
- Build and evaluate classification models for churn prediction
- Maintain a modular approach with multiple notebooks handling distinct tasks


---

## ğŸ“Š Dataset Overview

- **Source**: [Public telecom churn dataset (e.g., Kaggle or UCI)](https://github.com/ChaitanyaC22/Telecom-Churn-Prediction/blob/chai_main/Telecom_Churn_Prediction.ipynb)
- **Features**: Customer tenure, services used, charges, contract type, and more
- **Target**: `Churn` â€” whether the customer left the company

---

## ğŸ§  Methods Used

- ğŸ” **EDA**: Visualizations using Seaborn and Matplotlib to explore trends and distributions
- âš™ï¸ **Feature Engineering**: Handling categorical variables, outliers, and missing values
- ğŸ§ª **Modeling**:
  - Logistic Regression
  - Decision Trees
  - Random Forest
  - Gradient Boosting
- ğŸ“ˆ **Evaluation**: Accuracy, Precision, Recall, F1-Score, Confusion Matrix

---

## ğŸ› ï¸ Tools & Technologies

- Python, Pandas, NumPy
- Matplotlib, Seaborn
- Scikit-learn
- Jupyter Notebook

---

## ğŸ“Œ How to Use

1. Clone the repo or download the ZIP
2. Replace or update the dataset if needed in the `data/` folder

---

## ğŸ“ Insights

- Monthly charges, contract type, and tenure are major churn predictors
- Long-term customers under annual contracts show the lowest churn
- Random Forest and Gradient Boosting performed best in predictive accuracy


